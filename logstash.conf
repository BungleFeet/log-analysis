input {
  file {
    path => ["/var/log/geomag_logs/*_access_log*"]
    start_position => "beginning"
    tags => ["httpd-access", "local-file"]
  }
}

filter {
  # This "httpd-access" filter pipeline will parse events from access
  # logs generated by httpd
  if "httpd-access" in [tags] {

    # Drop any pings from F5 machine
    if [message] =~ "^-.*" {
      drop { }
    }

    # The following three filters recover the hostname from the source path,
    # and apply it to the @source_host field. This means the log messgages
    # will have the correct hostname when viewed in Graylog
    if "local-file" in [tags] {
      grok { match => [ "path", "%{HOST:hostname}_access_log" ] }
      mutate { replace => [ "host", "%{hostname}" ] }
      grok { match => [ "path", "_access_log\.%{WORD:host}" ] }
      mutate {
        remove_field => [ "path", "hostname" ]
        remove_tag => [ "local-file" ]
      }
    }

    # Parse the message as Common Apache Log format
    grok { match => [ "message", "%{COMMONAPACHELOG}" ] }

    # Drop any healthcheck pings from Monitis
    if [clientip] in ["67.215.13.74", "91.145.2.40", "46.23.67.107", "37.252.230.78", "79.125.4.86", "79.125.105.93", "54.247.180.199", "176.34.209.142", "176.34.216.57", "54.247.74.202", "54.247.85.237", "37.252.230.66"] {
      drop { }
    }

    # Convert numeric fields from strings
    mutate { convert => [ "bytes", "integer", "response", "integer" ] }

    # Replace the logstash-generated timestamp, which represents the time
    # at which the log message was received, with the timestamp parsed from
    # the log message.
    date {
      match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]
      remove_field => [ "timestamp" ]
    }
  }
}

output {
  elasticsearch {
    protocol => "http"
    host => "localhost"
    port => 9200
    flush_size => 50000
  }
}
